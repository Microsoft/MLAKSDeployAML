{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License.\n",
    "\n",
    "# Create Image\n",
    "In this notebook, we show the following steps for deploying a web service using AzureML:\n",
    "- Create an image\n",
    "- Test image locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure_utils.machine_learning.utils import load_configuration, get_workspace_from_config\n",
    "from azure_utils.utilities import text_to_json\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.model import Model\n",
    "from notebooks import directory\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "AML will use the following information to create an image, provision a cluster and deploy a service. Replace the \n",
    "values in the following cell with your information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_configuration(\"../workspace_conf.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "image_name = cfg['image_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Get workspace\n",
    "Load existing workspace from the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ws = get_workspace_from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'question_match_model'\n",
    "\n",
    "model = Model(ws, name=model_name)\n",
    "print(model.name, model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an image\n",
    "We will now modify the `score.py` created in the previous notebook for the `init()` function to use the model we \n",
    "registered to the workspace earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "import timeit as t\n",
    "from sklearn.externals import joblib\n",
    "from azureml.core.model import Model\n",
    "from azureml.contrib.services.aml_request import rawhttp\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from azure_utils.machine_learning.duplicate_model import DuplicateModel\n",
    "\n",
    "sys.path.append('./scripts/')\n",
    "\n",
    "\n",
    "def init():\n",
    "    logger = logging.getLogger(\"scoring_script\")\n",
    "    global model\n",
    "    model_name = 'question_match_model'\n",
    "    model_path = Model.get_model_path(model_name)\n",
    "    questions_path = './notebooks/data_folder/questions.tsv'\n",
    "    start = t.default_timer()\n",
    "    model = DuplicateModel(model_path, questions_path)\n",
    "    end = t.default_timer()\n",
    "    loadTimeMsg = \"Model loading time: {0} ms\".format(\n",
    "        round((end - start) * 1000, 2))\n",
    "    logger.info(loadTimeMsg)\n",
    "\n",
    "\n",
    "@rawhttp\n",
    "def run(request):\n",
    "    \"\"\"\n",
    "    Function runs on each request\n",
    "    \"\"\"\n",
    "    body = request.data\n",
    "    if request.method == 'POST':\n",
    "        logger = logging.getLogger(\"scoring_script\")\n",
    "        json_load_text = json.loads(body)\n",
    "        text_to_score = json_load_text['input']\n",
    "        start = t.default_timer()\n",
    "        resp = model.score(text_to_score)\n",
    "        end = t.default_timer()\n",
    "        logger.info(\"Prediction took {0} ms\".format(\n",
    "            round((end - start) * 1000, 2)))\n",
    "        return (json.dumps(resp))\n",
    "    if request.method == 'GET':\n",
    "        resp_body = {\n",
    "            \"azEnvironment\": \"Azure\",\n",
    "            \"location\": \"westus2\",\n",
    "            \"osType\": \"Ubuntu 16.04\",\n",
    "            \"resourceGroupName\": \"\",\n",
    "            \"resourceId\": \"\",\n",
    "            \"sku\": \"\",\n",
    "            \"subscriptionId\": \"\",\n",
    "            \"uniqueId\": \"PythonMLRST\",\n",
    "            \"vmSize\": \"\",\n",
    "            \"zone\": \"\",\n",
    "            \"isServer\": False,\n",
    "            \"version\": \"\"\n",
    "        }\n",
    "        return (resp_body)\n",
    "    return AMLResponse(\"bad request\", 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's specifiy the conda and pip dependencies for the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda_pack = [\"scikit-learn==0.19.1\", \"pandas==0.23.3\"]\n",
    "requirements = [\n",
    "    \"lightgbm==2.1.2\", \"azureml-defaults==1.0.57\", \"azureml-contrib-services\", \n",
    "    \"Microsoft-AI-Azure-Utility-Samples\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmenv = CondaDependencies.create(conda_packages=conda_pack,\n",
    "                                   pip_packages=requirements)\n",
    "\n",
    "with open(\"lgbmenv.yml\", \"w\") as f:\n",
    "    f.write(lgbmenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(\n",
    "    execution_script=\"score.py\",\n",
    "    runtime=\"python\",\n",
    "    conda_file=\"lgbmenv.yml\",\n",
    "    description=\"Image with lightgbm model\",\n",
    "    tags={\n",
    "        \"area\": \"text\",\n",
    "        \"type\": \"lightgbm\"\n",
    "    },\n",
    "    dependencies=[\n",
    "        \"./notebooks/data_folder/questions.tsv\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "image = ContainerImage.create(\n",
    "    name=image_name,\n",
    "    # this is the model object\n",
    "    models=[model],\n",
    "    image_config=image_config,\n",
    "    workspace=ws,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "image.wait_for_creation(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.name, image.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_version = str(image.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the logs of image creation in the following location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.image_build_log_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test image locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use one of the duplicate questions to test our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes_test_path = directory + '/data_folder/dupes_test.tsv'\n",
    "dupes_test = pd.read_csv(dupes_test_path, sep='\\t', encoding='latin1')\n",
    "text_to_score = dupes_test.iloc[0, 4]\n",
    "text_to_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_text = text_to_json(text_to_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "image.run(input_data=json_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have created a docker Image using AzureML and registred this image on Azure Container Registry (ACR). This docker \n",
    "image encapsulates a trained machine learning model and scoring scripts. In the next step, we can take this image \n",
    "and deploy it on the compute target of your choice: Azure Kubernetes Service (AKS) Cluster or Azure IoT Edge."
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "raymondl"
   }
  ],
  "kernelspec": {
   "display_name": "az-ml-realtime-score",
   "language": "python",
   "name": "az-ml-realtime-score"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}